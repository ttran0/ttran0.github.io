{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multilayer Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So I recently upgraded my desktop and now that I have a gtx 1070 card, I really wanted to get my hands on deep learning using my gpu. The library that I have decided to go with is Tensorflow. Tensorflow is a graph computation/deep learning library developed by Google. Tensorflow also has support for running on the gpu so that we can train larger and faster networks. This notebook will run through will include building a multilayer perceptron model on the classic MNIST dataset. \n",
    "\n",
    "The MNIST dataset includes samples of handwritten digits from 1 - 10. The objective is to train our network so that it can determine the digit in a given image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some examples of what each image looks like in the MNIST dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x203e068ec50>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x203df358198>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(mnist.train.images[3].reshape((28,28)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x203e06e63c8>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nKOIHiiJ+oCjiB4r6P+r5iX6RIOQqAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x203e2118c50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(mnist.train.images[0].reshape((28,28)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A multilayer perceptron model consists of an input layer, a hidden layer (or multiple hidden layers), and an output layer. \n",
    "\n",
    "<img src = \"https://upload.wikimedia.org/wikipedia/commons/c/c2/MultiLayerNeuralNetworkBigger_english.png\" style = \"width: 550px\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model will contain 3 hidden layers with the rectified linear unit (ReLU) function as our activation function. The ReLU function is defined as:\n",
    "$$\n",
    "f(x) = \n",
    "\\begin{cases} \n",
    "      1 & x > 0 \\\\\n",
    "      0 & otherwise\n",
    "   \\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n = 28 * 28\n",
    "num_classes = 10\n",
    "x = tf.placeholder(\"float\", [None, n])\n",
    "y = tf.placeholder(\"float\", [None, num_classes])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mlp(x, weights, bias):\n",
    "    # Hidden Layer 1\n",
    "    layer1 = tf.add(tf.matmul(x, weights['h1']), biases['b1'])\n",
    "    layer1 = tf.nn.relu(layer1)\n",
    "    \n",
    "    # Hidden Layer 2 \n",
    "    layer2 = tf.add(tf.matmul(layer1, weights['h2']), biases['b2'])\n",
    "    layer2 = tf.nn.relu(layer2)\n",
    "    \n",
    "    # Hidden Layer 3 \n",
    "    layer3 = tf.add(tf.matmul(layer2, weights['h3']), biases['b3'])\n",
    "    layer3 = tf.nn.relu(layer3)\n",
    "    \n",
    "    # Output Layer \n",
    "    output_layer = tf.matmul(layer3, weights['out']) + biases['out']\n",
    "    \n",
    "    return output_layer\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define our weights and biases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define weights and biases\n",
    "n_hidden1 = 256\n",
    "n_hidden2 = 256\n",
    "n_hidden3 = 256\n",
    "\n",
    "weights = {\n",
    "    'h1': tf.Variable(tf.random_normal([n, n_hidden1])), \n",
    "    'h2': tf.Variable(tf.random_normal([n_hidden1, n_hidden2])),\n",
    "    'h3': tf.Variable(tf.random_normal([n_hidden2, n_hidden3])),\n",
    "    'out': tf.Variable(tf.random_normal([n_hidden3, num_classes]))\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    'b1': tf.Variable(tf.random_normal([n_hidden1])), \n",
    "    'b2': tf.Variable(tf.random_normal([n_hidden2])), \n",
    "    'b3': tf.Variable(tf.random_normal([n_hidden3])),\n",
    "    'out': tf.Variable(tf.random_normal([num_classes]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "training_epochs = 50\n",
    "predictions = mlp(x, weights, biases)\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = predictions, labels = y))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = 0.001).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the stochastic gradient optimization algorithm to optimize our weights and biases with batch size 100. The stochastic gradient descent will randomly sample 100 of the images in our training set and train our model using 50 epochs to update our weights (1 pass forward in the network, and 1 pass backwards using backpropagation). The data has already been split into a training and testing set as part of a built in feature in Tensorflow. We just need to train our model and determine its accuracy by comparing it to the test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 cost= 936.272\n",
      "Epoch: 2 cost= 216.633\n",
      "Epoch: 3 cost= 146.919\n",
      "Epoch: 4 cost= 103.030\n",
      "Epoch: 5 cost= 82.060\n",
      "Epoch: 6 cost= 66.410\n",
      "Epoch: 7 cost= 58.126\n",
      "Epoch: 8 cost= 47.596\n",
      "Epoch: 9 cost= 41.920\n",
      "Epoch: 10 cost= 35.643\n",
      "Epoch: 11 cost= 31.135\n",
      "Epoch: 12 cost= 27.851\n",
      "Epoch: 13 cost= 25.317\n",
      "Epoch: 14 cost= 21.935\n",
      "Epoch: 15 cost= 20.035\n",
      "Epoch: 16 cost= 18.263\n",
      "Epoch: 17 cost= 16.363\n",
      "Epoch: 18 cost= 14.673\n",
      "Epoch: 19 cost= 12.848\n",
      "Epoch: 20 cost= 11.297\n",
      "Epoch: 21 cost= 11.236\n",
      "Epoch: 22 cost= 9.495\n",
      "Epoch: 23 cost= 9.143\n",
      "Epoch: 24 cost= 8.317\n",
      "Epoch: 25 cost= 7.601\n",
      "Epoch: 26 cost= 6.615\n",
      "Epoch: 27 cost= 6.030\n",
      "Epoch: 28 cost= 5.580\n",
      "Epoch: 29 cost= 5.029\n",
      "Epoch: 30 cost= 4.679\n",
      "Epoch: 31 cost= 4.614\n",
      "Epoch: 32 cost= 3.817\n",
      "Epoch: 33 cost= 3.542\n",
      "Epoch: 34 cost= 2.902\n",
      "Epoch: 35 cost= 3.418\n",
      "Epoch: 36 cost= 2.386\n",
      "Epoch: 37 cost= 2.389\n",
      "Epoch: 38 cost= 2.204\n",
      "Epoch: 39 cost= 2.047\n",
      "Epoch: 40 cost= 2.045\n",
      "Epoch: 41 cost= 1.595\n",
      "Epoch: 42 cost= 1.463\n",
      "Epoch: 43 cost= 1.447\n",
      "Epoch: 44 cost= 0.991\n",
      "Epoch: 45 cost= 1.069\n",
      "Epoch: 46 cost= 1.001\n",
      "Epoch: 47 cost= 0.912\n",
      "Epoch: 48 cost= 0.749\n",
      "Epoch: 49 cost= 0.737\n",
      "Epoch: 50 cost= 0.556\n",
      "Accuracy: 91.1700129509\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    \n",
    "    for epoch in range(training_epochs):\n",
    "        avg_cost = 0.\n",
    "        total_batch = int(mnist.train.num_examples/batch_size)\n",
    "        for i in range(total_batch):\n",
    "            \n",
    "            batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "                        \n",
    "            _, c = sess.run([optimizer, cost], feed_dict={x: batch_x,\n",
    "                                                          y: batch_y})\n",
    "            \n",
    "            avg_cost += c / total_batch\n",
    "\n",
    "        print (\"Epoch:\", '%0d' % (epoch+1), \"cost=\", \"{:.3f}\".format(avg_cost))\n",
    "\n",
    "    \n",
    "    pred = tf.equal(tf.argmax(predictions, 1), tf.argmax(y, 1))\n",
    "    acc = tf.reduce_mean(tf.cast(pred, \"float\"))\n",
    "    print (\"Accuracy:\", acc.eval({x: mnist.test.images, y: mnist.test.labels}) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With 50 epochs, a 3 hidden layer multilayer perceptron optimized with stochastic gradient descent, we achieve a 91% accuracy. This accuracy is actually not that great compared to what other models can do. One way to improve on this model is introduce convolution and pooling layers, more commonly known as a convolutional neural network, which is what I will be working on next to get a better accuracy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
